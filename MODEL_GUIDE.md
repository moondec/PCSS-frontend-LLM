# PCSS LLM Model Guide / Przewodnik po Modelach PCSS

This document provides a summary of models available in the application, categorized by their use cases and strengths.
*Ten dokument zawiera zestawienie modeli dostÄ™pnych w aplikacji, z podziaÅ‚em na ich zastosowania i mocne strony.*

---

## âš ï¸ IMPORTANT: Exact API Model Names / WAÅ»NE: DokÅ‚adne nazwy modeli w API

**Use these EXACT names when selecting models in the application:**  
**UÅ¼ywaj tych DOKÅADNYCH nazw przy wyborze modeli w aplikacji:**

| Model Category | Exact API Name | Description |
|----------------|----------------|-------------|
| **Polish** | `bielik_11b` | Polish specialized (11B params) |
| **Polish** | `bielik_4.5b` | Polish smaller (4.5B params) |
| **General** | `DeepSeek-V3.1-vLLM` | Logic, math, coding (long context) |
| **General** | `DeepSeek-V3.1-vLLM-2` | Alternative instance |
| **General** | `llama3.3:70b` | Meta's general purpose (70B) |
| **General** | `Qwen2.5:72b` | Alibaba's math/coding model (72B) |
| **Coding** | `qwen3-coder:30b` | Specialized coding model (30B) |
| **Coding** | `Mistral-Small-3.2:24b` | Fast coding/efficiency (24B) |
| **Medical** | `Meditron3:70b` | Medical specialization |
| **Biology** | `OpenBioLLM:70b` | Biology/biomedicine |
| **Tools** | `Nanonets-OCR-s` | OCR (not for chat) |
| **Experimental** | `gpt-oss_120b` | PCSS experimental |
| **Experimental** | `gpt-oss_20b` | PCSS experimental |

> **Note:** Model names are case-sensitive and must match exactly (e.g., `bielik_11b` NOT `Bielik-11B-v2`)  
> **Uwaga:** Nazwy modeli sÄ… wraÅ¼liwe na wielkoÅ›Ä‡ liter i muszÄ… byÄ‡ dokÅ‚adne (np. `bielik_11b` NIE `Bielik-11B-v2`)

---

## ğŸ‡¬ğŸ‡§ English Version

### ğŸ‡µğŸ‡± Polish Models (Specialized)
Best for Polish language, culture, and grammar tasks.

*   **Bielik-11b** (`bielik_11b`)
    *   **Architecture:** SpeakLeash (based on Solar/Mistral).
    *   **Best for:** Official letters, emails in Polish, summarizing Polish texts, tasks requiring correct inflection.
    *   **Note:** The "default" model for Polish tasks.

*   **Bielik-4.5b** (`bielik_4.5b`)
    *   **Architecture:** Smaller version of Bielik.
    *   **Best for:** Quick responses, simple translations, running on lower-end hardware (if local).

### ğŸ§  General Purpose Giants
Powerful models with general knowledge, comparable to GPT-4.

*   **DeepSeek-V3.1** (`DeepSeek-V3.1-vLLM` or `DeepSeek-V3.1-vLLM-2`)
    *   **Strengths:** Logic, mathematics, coding, very long context.
    *   **Best for:** Solving reasoning puzzles, analyzing long documents, writing code.

*   **GPT-4o (OpenAI)**
    *   **Availability:** Currently **NOT AVAILABLE** on PCSS (use for text tasks only if available in list).
    *   **Note:** Multi-modal features (vision) are disabled.

*   **Llama 3.3** (`llama3.3:70b`)
    *   **Maker:** Meta.
    *   **Strengths:** Solid general model, great writing style.
    *   **Best for:** Content generation in English and Polish, brainstorming, general assistance.

*   **Qwen2.5** (`Qwen2.5:72b`)
    *   **Maker:** Alibaba.
    *   **Strengths:** Often tops Open Source leaderboards. Excellent in math and coding.
    *   **Best for:** Complex instructions, STEM tasks.

### ğŸ’» Coding
Models trained specifically to understand programming languages.

*   **Qwen3-Coder** (`qwen3-coder:30b`)
    *   **Specialization:** Programming.
    *   **Best for:** Writing scripts (Python, JS, C++), debugging, explaining code. Often outperforms general 70B models at code.

*   **Mistral-Small** (`Mistral-Small-3.2:24b`)
    *   **Strengths:** Speed and efficiency. Great quality-to-speed ratio.
    *   **Best for:** Quick scripts, refactoring, simple technical questions.

### âš•ï¸ Medicine & Science (Specialized)
Models with specialized domain knowledge.

*   **Meditron3** (`Meditron3:70b`)
    *   **Specialization:** Medicine.
    *   **Best for:** Answering medical questions, analyzing clinical cases, summarizing medical literature.
    *   **Warning:** For educational/research purposes only, does not replace a doctor.

*   **OpenBioLLM** (`OpenBioLLM:70b`)
    *   **Specialization:** Biology and biomedicine.
    *   **Best for:** Working with scientific publications in biology, genetics, and pharmacy.

### ğŸ› ï¸ Tools

*   **Nanonets-OCR** (`Nanonets-OCR-s`)
    *   **Type:** OCR (Optical Character Recognition).
    *   **Use:** Not a chatbot. Extracts text from images, scans, and PDF files without a text layer.

*   **gpt-oss_120b / 20b**
    *   **Type:** Experimental/Internal PCSS models.
    *   **Use:** Likely large open-source models (e.g., Falcon or Mixtral) for testing. Worth trying if others fail at specific tasks.

---

## ğŸ‡µğŸ‡± Wersja Polska

### ğŸ‡µğŸ‡± Modele Polskie (Specjalizowane)
Te modele najlepiej radzÄ… sobie z jÄ™zykiem polskim, naszÄ… kulturÄ… i gramatykÄ….

*   **Bielik-11b** (`bielik_11b`)
    *   **Architektura:** SpeakLeash (bazujÄ…cy na Solar/Mistral).
    *   **Najlepsze do:** Pisania pism urzÄ™dowych, e-maili po polsku, streszczania polskich tekstÃ³w, zadaÅ„ wymagajÄ…cych poprawnej odmiany fleksyjnej.
    *   **Uwagi:** Model "domyÅ›lny" dla zadaÅ„ w jÄ™zyku polskim.

*   **Bielik-4.5b** (`bielik_4.5b`)
    *   **Architektura:** Mniejsza wersja Bielika.
    *   **Najlepsze do:** Szybkich odpowiedzi, prostych tÅ‚umaczeÅ„, dziaÅ‚ania na sÅ‚abszym sprzÄ™cie (gdyby byÅ‚ uruchamiany lokalnie).

### ğŸ§  Wszechstronne Giganty (General Purpose)
NajpotÄ™Å¼niejsze modele o ogÃ³lnej wiedzy, porÃ³wnywalne z GPT-4.

*   **DeepSeek-V3.1** (`DeepSeek-V3.1-vLLM` lub `DeepSeek-V3.1-vLLM-2`)
    *   **Mocne strony:** Logika, matematyka, programowanie, bardzo dÅ‚ugi kontekst.
    *   **Najlepsze do:** RozwiÄ…zywania zagadek logicznych, analizy dÅ‚ugich dokumentÃ³w, pisania kodu.

*   **GPT-4o (OpenAI)**
    *   **DostÄ™pnoÅ›Ä‡:** Obecnie **NIEDOSTÄ˜PNY** na PCSS (uÅ¼ywaj do zadaÅ„ tekstowych tylko jeÅ›li jest na liÅ›cie).
    *   **Uwaga:** Funkcje multimodalne (wizja) sÄ… wyÅ‚Ä…czone.

*   **Llama 3.3** (`llama3.3:70b`)
    *   **Producent:** Meta.
    *   **Mocne strony:** Bardzo solidny model ogÃ³lny, Å›wietny styl wypowiedzi.
    *   **Najlepsze do:** Generowania treÅ›ci po angielsku i polsku, burze mÃ³zgÃ³w, asystent ogÃ³lny.

*   **Qwen2.5** (`Qwen2.5:72b`)
    *   **Producent:** Alibaba.
    *   **Mocne strony:** CzÄ™sto wygrywa rankingi Open Source. Åšwietny w matematyce i kodowaniu.
    *   **Najlepsze do:** Skomplikowanych instrukcji, zadaÅ„ Å›cisÅ‚ych.

### ğŸ’» Programowanie i Kod (Coding)
Modele wytrenowane specjalnie do rozumienia jÄ™zykÃ³w programowania.

*   **Qwen3-Coder** (`qwen3-coder:30b`)
    *   **Specjalizacja:** Programowanie.
    *   **Najlepsze do:** Pisania skryptÃ³w (Python, JS, C++), debugowania, wyjaÅ›niania kodu. Radzi sobie lepiej z kodem niÅ¼ ogÃ³lne modele 70B.

*   **Mistral-Small** (`Mistral-Small-3.2:24b`)
    *   **Mocne strony:** SzybkoÅ›Ä‡ i efektywnoÅ›Ä‡. Bardzo dobry stosunek jakoÅ›ci do prÄ™dkoÅ›ci.
    *   **Najlepsze do:** Szybkich skryptÃ³w, refaktoryzacji, prostych pytaÅ„ technicznych.

### âš•ï¸ Medycyna i Nauka (Specialized)
Modele posiadajÄ…ce specjalistycznÄ… wiedzÄ™ dziedzinowÄ….

*   **Meditron3** (`Meditron3:70b`)
    *   **Specjalizacja:** Medycyna.
    *   **Najlepsze do:** Odpowiadania na pytania medyczne, analizy przypadkÃ³w klinicznych, streszczania literatury medycznej.
    *   **OstrzeÅ¼enie:** SÅ‚uÅ¼y do celÃ³w edukacyjnych/badawczych, nie zastÄ™puje lekarza.

*   **OpenBioLLM** (`OpenBioLLM:70b`)
    *   **Specjalizacja:** Biologia i biomedycyna.
    *   **Najlepsze do:** Pracy z publikacjami naukowymi z zakresu biologii, genetyki i farmacji.

### ğŸ› ï¸ NarzÄ™dzia

*   **Nanonets-OCR** (`Nanonets-OCR-s`)
    *   **Typ:** OCR (Optical Character Recognition).
    *   **Zastosowanie:** To nie jest chatbot. SÅ‚uÅ¼y do wyciÄ…gania tekstu ze zdjÄ™Ä‡, skanÃ³w dokumentÃ³w i plikÃ³w PDF, ktÃ³re nie majÄ… warstwy tekstowej.

*   **gpt-oss_120b / 20b**
    *   **Typ:** Modele eksperymentalne/wewnÄ™trzne PCSS.
    *   **Zastosowanie:** Prawdopodobnie duÅ¼e modele open-source (np. Falcon lub Mixtral) udostÄ™pnione testowo. Warto sprawdziÄ‡, jeÅ›li inne modele nie dajÄ… rady w specyficznych zadaniach.
